{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest acquisitions session path on bl_new_acquisition.Acquisitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local configuration file found !!, no need to run the configuration (unless configuration has changed)\n"
     ]
    }
   ],
   "source": [
    "from scripts.conf_file_finding import try_find_conf_file\n",
    "try_find_conf_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting alvaros@datajoint01.pni.princeton.edu:3306\n"
     ]
    }
   ],
   "source": [
    "import datajoint as dj\n",
    "import pandas as pd\n",
    "import utility.path_utility as pu\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import bl_pipeline.acquisition as acq\n",
    "\n",
    "new_lab = dj.create_virtual_module('new_lab', 'bl_new_lab')\n",
    "new_subject = dj.create_virtual_module('new_subject', 'bl_new_subject')\n",
    "new_acquisition = dj.create_virtual_module('new_acquisition', 'bl_new_acquisition')\n",
    "\n",
    "#bdata          = dj.create_virtual_module('bdata', 'bl_bdata')\n",
    "#shadow_acquisition = dj.create_virtual_module('shadow_acquisition', 'bl_shadow_acquisition')\n",
    "#new_acquisition = dj.create_virtual_module('new_acquisition', 'bl_new_acquisition')\n",
    "#new_lab = dj.create_virtual_module('new_lav', 'bl_new_lab')\n",
    "#ratinfo        = dj.create_virtual_module('ratinfo', 'bl_ratinfo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get all directories with raw acquisition from root_ephys_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sg/5bw1t8p11nx09k7kmytnmfb40000gp/T/ipykernel_2899/818443775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstr_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mrel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mstatus_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_file_pattern_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_pattern_ephys_session\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_np_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_childs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MATLAB/BrainCogsProjects/Datajoint_proj/bl_pipeline_python/utility/path_utility.py\u001b[0m in \u001b[0;36mcheck_file_pattern_dir\u001b[0;34m(filepath, file_patterns, search_childs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchild_dirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_patterns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mfound_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mpatterns_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bl_pipeline_python_env3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pathname, recursive)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bl_pipeline_python_env3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mglob_in_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_glob0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob_in_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bl_pipeline_python_env3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_glob1\u001b[0;34m(dirname, pattern, dironly)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_glob1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bl_pipeline_python_env3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_iterdir\u001b[0;34m(dirname, dironly)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdironly\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "root_dir = pathlib.Path(dj.config['custom']['ephys_root_data_dir'])\n",
    "\n",
    "fields_t_acq  = pd.DataFrame.from_dict(acq.Acquisitions.heading.attributes, orient='index')\n",
    "acquisitions_found = 0\n",
    "acquisition_df = pd.DataFrame(columns=fields_t_acq.index.to_list()) \n",
    "acquisition_df = acquisition_df.drop(columns=['acquisition_id', 'user_id', 'acquisition_sessid'])\n",
    "\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for dirname in dirs:\n",
    "        aux_dir = pathlib.Path(os.path.join(root, dirname))\n",
    "        str_dir = str(aux_dir.as_posix())\n",
    "        rel_dir = str_dir.replace(str(root_dir), \"\")\n",
    "        status_dir = pu.check_file_pattern_dir(str(aux_dir), pu.file_pattern_ephys_session['raw_np_files'], search_childs=False)\n",
    "        \n",
    "        if status_dir: \n",
    "            acquisitions_found += 1\n",
    "            acquisition_df.loc[len(acquisition_df.index), 'acquisition_raw_rel_path'] = rel_dir\n",
    "            \n",
    "acquisition_df            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a Get all directories with sorted results from clusterings_root_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sg/5bw1t8p11nx09k7kmytnmfb40000gp/T/ipykernel_2899/1236584823.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mstr_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mrel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mstatus_dir_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_file_pattern_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_pattern_ephys_session\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sorted_np_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_childs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus_dir_sorted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MATLAB/BrainCogsProjects/Datajoint_proj/bl_pipeline_python/utility/path_utility.py\u001b[0m in \u001b[0;36mcheck_file_pattern_dir\u001b[0;34m(filepath, file_patterns, search_childs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchild_dirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_patterns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mfound_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mpatterns_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bl_pipeline_python_env3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pathname, recursive)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bl_pipeline_python_env3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mglob_in_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_glob0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob_in_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bl_pipeline_python_env3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_glob1\u001b[0;34m(dirname, pattern, dironly)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_glob1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bl_pipeline_python_env3/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_iterdir\u001b[0;34m(dirname, dironly)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sorted_dir = pathlib.Path(dj.config['custom']['clusterings_root_data_dir'])\n",
    "\n",
    "fields_t_sort = pd.DataFrame.from_dict(acq.Sortings.heading.attributes, orient='index')\n",
    "sorted_found = 0\n",
    "sorted_df = pd.DataFrame(columns=fields_t_sort.index.to_list()) \n",
    "sorted_df = sorted_df.drop(columns=['acquisition_id', 'sorting_id'])\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for dirname in dirs:\n",
    "        aux_dir = pathlib.Path(os.path.join(root, dirname))\n",
    "        str_dir = str(aux_dir.as_posix())\n",
    "        rel_dir = str_dir.replace(str(root_dir), \"\") \n",
    "        status_dir_sorted = pu.check_file_pattern_dir(str(aux_dir), pu.file_pattern_ephys_session['sorted_np_files'], search_childs=False)\n",
    "        \n",
    "        if status_dir_sorted: \n",
    "            sorted_found += 1\n",
    "            sorted_df.loc[len(sorted_df.index), 'acquisition_post_rel_path'] = rel_dir            \n",
    "    #if acquisitions_found > 100:\n",
    "        #break\n",
    "        \n",
    "        \n",
    "sorted_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Infer subject and rat from path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_df['acquisition_type'] = 'ephys'\n",
    "acquisition_df['experimenter'] = acquisition_df['acquisition_raw_rel_path'].str.split('/').str[1]\n",
    "acquisition_df['acquisition_rat'] = acquisition_df['acquisition_raw_rel_path'].str.split('/').str[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get experimenter user_id and merge with corresponding acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acquisition_rat</th>\n",
       "      <th>acquisition_type</th>\n",
       "      <th>acquisition_raw_rel_path</th>\n",
       "      <th>user_id</th>\n",
       "      <th>experimenter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [acquisition_rat, acquisition_type, acquisition_raw_rel_path, user_id, experimenter]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contact_df = pd.DataFrame(new_lab.Contacts.fetch('user_id', 'experimenter', as_dict=True))\n",
    "acquisition_df_nouser = acquisition_df.copy()\n",
    "acquisition_df = acquisition_df.merge(contact_df, on='experimenter', how='inner')\n",
    "acquisition_df_nouser = acquisition_df_nouser.merge(contact_df, on='experimenter', how='left')\n",
    "acquisition_df_nouser = acquisition_df_nouser.loc[acquisition_df_nouser['user_id'].isnull(), :]\n",
    "acquisition_df_nouser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Check corresponding ratname and filter non matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acquisition_rat</th>\n",
       "      <th>acquisition_type</th>\n",
       "      <th>acquisition_raw_rel_path</th>\n",
       "      <th>user_id</th>\n",
       "      <th>experimenter</th>\n",
       "      <th>ratname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [acquisition_rat, acquisition_type, acquisition_raw_rel_path, user_id, experimenter, ratname]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_df = pd.DataFrame(new_subject.Rats.fetch('ratname', as_dict=True))\n",
    "acquisition_df_norat = acquisition_df.copy()\n",
    "acquisition_df = acquisition_df.merge(subject_df, left_on='acquisition_rat', right_on='ratname', how='inner')\n",
    "acquisition_dfnorat = acquisition_df_norat.merge(subject_df, left_on='acquisition_rat', right_on='ratname', how='left')\n",
    "acquisition_dfnorat = acquisition_dfnorat.loc[acquisition_dfnorat['ratname'].isnull(), :]\n",
    "acquisition_dfnorat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Check corresponding session and add it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acquisition_rat</th>\n",
       "      <th>acquisition_type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>experimenter</th>\n",
       "      <th>ratname</th>\n",
       "      <th>acquisition_sessid</th>\n",
       "      <th>acquisition_raw_rel_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [acquisition_rat, acquisition_type, user_id, experimenter, ratname, acquisition_sessid, acquisition_raw_rel_path]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ephys_session_df = pd.DataFrame(new_acquisition.AcquisitionSessions.fetch('sessid', 'acquisition_raw_rel_path', as_dict=True))\n",
    "ephys_session_df = ephys_session_df.rename(columns={'sessid':'acquisition_sessid'})\n",
    "acquisition_df_nosession = acquisition_df.copy()\n",
    "acquisition_df = acquisition_df.merge(ephys_session_df, on='acquisition_raw_rel_path', how='left')\n",
    "acquisition_df_nosession = acquisition_df_nosession.merge(ephys_session_df, on='acquisition_raw_rel_path', how='left')\n",
    "acquisition_df_nosession = acquisition_df_nosession.loc[acquisition_df_nosession['acquisition_sessid'].isnull(), :]\n",
    "acquisition_df_nosession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Insert all acquisitions found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_df = acquisition_df.drop(columns=['experimenter', 'ratname'])\n",
    "acq.Acquisitions.insert(acquisition_df, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acquisition_id</th>\n",
       "      <th>acquisition_sessid</th>\n",
       "      <th>acquisition_rat</th>\n",
       "      <th>user_id</th>\n",
       "      <th>acquisition_type</th>\n",
       "      <th>acquisition_raw_rel_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>A242</td>\n",
       "      <td>abondy</td>\n",
       "      <td>ephys</td>\n",
       "      <td>/Adrian/A242/2019-06-10_g0/2019-06-10_g0_imec0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>A242</td>\n",
       "      <td>abondy</td>\n",
       "      <td>ephys</td>\n",
       "      <td>/Adrian/A242/2019-06-05_g0/2019-06-05_g0_imec0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>A242</td>\n",
       "      <td>abondy</td>\n",
       "      <td>ephys</td>\n",
       "      <td>/Adrian/A242/2019-06-20_g0/2019-06-20_g0_imec0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>A242</td>\n",
       "      <td>abondy</td>\n",
       "      <td>ephys</td>\n",
       "      <td>/Adrian/A242/2019-06-04_g0/2019-06-04_g0_imec0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>A242</td>\n",
       "      <td>abondy</td>\n",
       "      <td>ephys</td>\n",
       "      <td>/Adrian/A242/2019-05-30_g0/2019-05-30_g0_imec0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>241</td>\n",
       "      <td>None</td>\n",
       "      <td>A241</td>\n",
       "      <td>abondy</td>\n",
       "      <td>ephys</td>\n",
       "      <td>/Adrian/A241/no point sorting/very low trial c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>242</td>\n",
       "      <td>None</td>\n",
       "      <td>A241</td>\n",
       "      <td>abondy</td>\n",
       "      <td>ephys</td>\n",
       "      <td>/Adrian/A241/no point sorting/very low trial c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>243</td>\n",
       "      <td>None</td>\n",
       "      <td>A241</td>\n",
       "      <td>abondy</td>\n",
       "      <td>ephys</td>\n",
       "      <td>/Adrian/A241/no point sorting/very low trial c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>244</td>\n",
       "      <td>None</td>\n",
       "      <td>A241</td>\n",
       "      <td>abondy</td>\n",
       "      <td>ephys</td>\n",
       "      <td>/Adrian/A241/no point sorting/very low trial c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>245</td>\n",
       "      <td>None</td>\n",
       "      <td>A241</td>\n",
       "      <td>abondy</td>\n",
       "      <td>ephys</td>\n",
       "      <td>/Adrian/A241/no point sorting/very low trial c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     acquisition_id acquisition_sessid acquisition_rat user_id  \\\n",
       "0                 1               None            A242  abondy   \n",
       "1                 2               None            A242  abondy   \n",
       "2                 3               None            A242  abondy   \n",
       "3                 4               None            A242  abondy   \n",
       "4                 5               None            A242  abondy   \n",
       "..              ...                ...             ...     ...   \n",
       "240             241               None            A241  abondy   \n",
       "241             242               None            A241  abondy   \n",
       "242             243               None            A241  abondy   \n",
       "243             244               None            A241  abondy   \n",
       "244             245               None            A241  abondy   \n",
       "\n",
       "    acquisition_type                           acquisition_raw_rel_path  \n",
       "0              ephys     /Adrian/A242/2019-06-10_g0/2019-06-10_g0_imec0  \n",
       "1              ephys     /Adrian/A242/2019-06-05_g0/2019-06-05_g0_imec0  \n",
       "2              ephys     /Adrian/A242/2019-06-20_g0/2019-06-20_g0_imec0  \n",
       "3              ephys     /Adrian/A242/2019-06-04_g0/2019-06-04_g0_imec0  \n",
       "4              ephys     /Adrian/A242/2019-05-30_g0/2019-05-30_g0_imec0  \n",
       "..               ...                                                ...  \n",
       "240            ephys  /Adrian/A241/no point sorting/very low trial c...  \n",
       "241            ephys  /Adrian/A241/no point sorting/very low trial c...  \n",
       "242            ephys  /Adrian/A241/no point sorting/very low trial c...  \n",
       "243            ephys  /Adrian/A241/no point sorting/very low trial c...  \n",
       "244            ephys  /Adrian/A241/no point sorting/very low trial c...  \n",
       "\n",
       "[245 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acquisition_db_df = pd.DataFrame(acq.Acquisitions.fetch(as_dict=True))\n",
    "acquisition_db_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Merge acquisitions and sortings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acquisition_id_x</th>\n",
       "      <th>acquisition_post_rel_path</th>\n",
       "      <th>acquisition_raw_rel_path</th>\n",
       "      <th>acquisition_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>/Adrian/A242/2019-06-10_g0/2019-06-10_g0_imec0</td>\n",
       "      <td>/Adrian/A242/2019-06-10_g0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>/Adrian/A242/2019-05-30_g0/2019-05-30_g0_imec0</td>\n",
       "      <td>/Adrian/A242/2019-05-30_g0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>/Adrian/A242/2019-06-06_g0/2019-06-06_g0_imec0</td>\n",
       "      <td>/Adrian/A242/2019-06-06_g0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>/Adrian/A242/2019-06-07_g0/2019-06-07_g0_imec0</td>\n",
       "      <td>/Adrian/A242/2019-06-07_g0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>/Adrian/A242/2019-05-31_g0/2019-05-31_g0_imec0</td>\n",
       "      <td>/Adrian/A242/2019-05-31_g0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>/Adrian/A242/2019-06-03_g0/2019-06-03_g0_imec0</td>\n",
       "      <td>/Adrian/A242/2019-06-03_g0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>/Adrian/A230/2019-07-15_g0/2019-07-15_g0_t0.imec0</td>\n",
       "      <td>/Adrian/A230/2019-07-15_g0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  acquisition_id_x                          acquisition_post_rel_path  \\\n",
       "0              NaN     /Adrian/A242/2019-06-10_g0/2019-06-10_g0_imec0   \n",
       "1              NaN     /Adrian/A242/2019-05-30_g0/2019-05-30_g0_imec0   \n",
       "2              NaN     /Adrian/A242/2019-06-06_g0/2019-06-06_g0_imec0   \n",
       "3              NaN     /Adrian/A242/2019-06-07_g0/2019-06-07_g0_imec0   \n",
       "4              NaN     /Adrian/A242/2019-05-31_g0/2019-05-31_g0_imec0   \n",
       "5              NaN     /Adrian/A242/2019-06-03_g0/2019-06-03_g0_imec0   \n",
       "6              NaN  /Adrian/A230/2019-07-15_g0/2019-07-15_g0_t0.imec0   \n",
       "\n",
       "     acquisition_raw_rel_path  acquisition_id_y  \n",
       "0  /Adrian/A242/2019-06-10_g0               NaN  \n",
       "1  /Adrian/A242/2019-05-30_g0               NaN  \n",
       "2  /Adrian/A242/2019-06-06_g0               NaN  \n",
       "3  /Adrian/A242/2019-06-07_g0               NaN  \n",
       "4  /Adrian/A242/2019-05-31_g0               NaN  \n",
       "5  /Adrian/A242/2019-06-03_g0               NaN  \n",
       "6  /Adrian/A230/2019-07-15_g0               NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acquisition_db_df = acquisition_db_df[['acquisition_raw_rel_path', 'acquisition_id']].copy()\n",
    "sorted_df['acquisition_raw_rel_path'] = sorted_df.apply(lambda x: get_parent_dir(x['acquisition_post_rel_path']), axis=1)\n",
    "\n",
    "sorted_df2 = sorted_df.merge(acquisition_db_df, on='acquisition_raw_rel_path', how='left')\n",
    "\n",
    "sorted_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acquisition_id</th>\n",
       "      <th>acquisition_post_rel_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [acquisition_id, acquisition_post_rel_path]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sorted session processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Construct and find nominal paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_root = dj.config['custom']['clustering_root_data_dir']\n",
    "raw_sessions_df_found['subject_cluster_path'] = raw_sessions_df_found.apply(lambda x: pu.combine_str_path(cluster_root, [x['experimenter'], x['session_rat']]), axis=1)\n",
    "raw_sessions_df_found['nominal_cluster_session_path'] = raw_sessions_df_found.apply(lambda x: pu.check_date_directory(x['subject_cluster_path'], x['session_date']), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Filter only sessions with nominal path found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sessions_df_nom_path_found = raw_sessions_df_found.loc[~raw_sessions_df_found['nominal_cluster_session_path'].isin(pu.path_not_found_dict.values()), :]\n",
    "cluster_sessions_df_nom_path_found = cluster_sessions_df_nom_path_found.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Enumerate all possible directories for each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If multiple paths found, this will create a record for each \"possibility\"\n",
    "cluster_sessions_df_nom_path_found = cluster_sessions_df_nom_path_found.explode(['nominal_cluster_session_path'])\n",
    "cluster_sessions_df_nom_path_found = cluster_sessions_df_nom_path_found.sort_values(by=['sessid'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Find session files in nominal directories and childs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sessions_df_nom_path_found['real_cluster_session_path'] =\\\n",
    "cluster_sessions_df_nom_path_found.apply(lambda x: pu.find_file_pattern_dir(x['nominal_cluster_session_path'],\\\n",
    "                                                                     pu.file_pattern_ephys_session['sorted_np_files']),axis=1)\n",
    "\n",
    "#If several recoring files are found inside a \"parent\" path\n",
    "cluster_sessions_df_nom_path_found = cluster_sessions_df_nom_path_found.explode(['real_cluster_session_path'])\n",
    "\n",
    "\n",
    "cluster_sessions_df_found = cluster_sessions_df_nom_path_found.loc[~cluster_sessions_df_nom_path_found['real_cluster_session_path'].isin(pu.path_not_found_dict.values()), :]\n",
    "cluster_sessions_df_found['cluster_session_rel_path'] = cluster_sessions_df_found.loc[:,'real_cluster_session_path'].str.replace(dj.config['custom']['clustering_root_data_dir'], '', regex=False)\n",
    "cluster_sessions_df_found = cluster_sessions_df_found.reset_index(drop=True)\n",
    "cluster_sessions_df_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Ingest into DB (preAcquisitionSession)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Add/Select columns from the DF --> DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count how many possible directories for each session we have\n",
    "cluster_sessions_df_found['directory_num'] =  cluster_sessions_df_found.groupby('sessid').cumcount()\n",
    "cluster_sessions_df_found = cluster_sessions_df_found.reset_index(drop=True)\n",
    "\n",
    "\n",
    "cluster_sessions_df_found = cluster_sessions_df_found.rename(columns={\"cluster_session_rel_path\": \"acquisition_post_rel_path\",\\\n",
    "                                          \"raw_session_rel_path\": \"acquisition_raw_rel_path\"})\n",
    "\n",
    "cluster_sessions_df_found['acquisition_type'] = 'ephys'\n",
    "cluster_sessions_df_found['correct_dirs'] = 0\n",
    "\n",
    "pre_acquisition_sessions_df = cluster_sessions_df_found[new_acquisition.PreAcquisitionSessions.heading.names]\n",
    "pre_acquisition_sessions_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so = pre_acquisition_sessions_df.groupby('directory_num').max()\n",
    "pre_acquisition_sessions_df.loc[pre_acquisition_sessions_df['sessid'] == 710898, 'acquisition_post_rel_path'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Ingest to preAcquisitionSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keys = pre_acquisition_sessions_df.to_dict(orient='records')\n",
    "for i in dict_keys:\n",
    "    new_acquisition.PreAcquisitionSessions.insert1(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Update correct_dirs of known PreAcquisitionSessions (triggers AcquisitionSessions insert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1  Fetch from PreAcquisitionSessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preacq_sessions_df = pd.DataFrame(new_acquisition.PreAcquisitionSessions.fetch(order_by='sessid desc', as_dict=True))\n",
    "idx_duplicate_raw = preacq_sessions_df['sessid'].duplicated(keep=False)\n",
    "preacq_sessions_df = preacq_sessions_df[~idx_duplicate_raw]\n",
    "preacq_sessions_df = preacq_sessions_df.loc[preacq_sessions_df['directory_num'] == 0, :]\n",
    "preacq_sessions_df = preacq_sessions_df.reset_index(drop=True)\n",
    "preacq_sessions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Find unequivocally relation between directories and session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_duplicate_raw = preacq_sessions_df['acquisition_raw_rel_path'].duplicated(keep=False)\n",
    "preacq_sessions_df_unique_raw = preacq_sessions_df[~idx_duplicate_raw]\n",
    "preacq_sessions_df_unique_raw = preacq_sessions_df_unique_raw.reset_index(drop=True)\n",
    "idx_duplicate_post = preacq_sessions_df_unique_raw['acquisition_post_rel_path'].duplicated(keep=False)\n",
    "acq_sessions_df_unique = preacq_sessions_df_unique_raw[~idx_duplicate_post]\n",
    "acq_sessions_df_unique = acq_sessions_df_unique.reset_index(drop=True)\n",
    "acq_sessions_df_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Update correct_dir of found session trigger ingest acquisitionSessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(acq_sessions_df_unique.shape[0]):\n",
    "    key = dict()\n",
    "    key['sessid'] = acq_sessions_df_unique.loc[i, 'sessid']\n",
    "    key['directory_num'] = 0\n",
    "    key['correct_dirs'] =  1\n",
    "    (new_acquisition.PreAcquisitionSessions).update1(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Check AcquisitionSessions records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_sessions_df = pd.DataFrame(new_acquisition.AcquisitionSessions.fetch(order_by='sessid desc', as_dict=True))\n",
    "acq_sessions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69b99f51e057dae8bf7af0dfb3c6eb1984d102baaea9585d96e379423a8ef19c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
